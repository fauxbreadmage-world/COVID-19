---
title: "COVID-19 Analysis"
author: "NA"
date: "`r Sys.Date()`"
output: html_document
---
```{css, echo=FALSE}
body {
  background-color: #f5f5f5;  /* This is a light gray color. */
}

```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(leaflet)
library(leaflet.extras)
library(sf)
library(lmtest)
```

## The Data 

This data consists of COVID-19 cases and deaths both globally and in the U.S.A. This is time series data that shows the cases and deaths over time. Included in the U.S. data is population by state and the global data will be joined with country population. 

The data is available here:
https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series

## Purpose

This report will be examining this data and comparing the impact score (defined by death/cases*100) of COVID-19 by both U.S. State and Country to see where COVID-19 had the highest proportion of deaths to cases. 

### Load the data

```{r}
# Load the dataset
get_url <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/"
file_names <- c("time_series_covid19_confirmed_global.csv",
                "time_series_covid19_deaths_global.csv",
                "time_series_covid19_confirmed_US.csv",
                "time_series_covid19_deaths_US.csv")
urls <- str_c(get_url, file_names)

global_cases <- read_csv(urls[1])
global_deaths <- read_csv(urls[2])
US_cases <- read_csv(urls[3])
US_deaths <- read_csv(urls[4])

# Get population data for global
uid_lookup_url <- "https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/UID_ISO_FIPS_LookUp_Table.csv"

# Load US states shapefile data
us_states <- st_read("https://raw.githubusercontent.com/PublicaMundi/MappingAPI/master/data/geojson/us-states.json", quiet = TRUE)

```

### Clean and transform

Since we are looking at the both by U.S. State and by country we want the data structures to look as similar as possible.

Here will be cleaning both and doing the necessary transformation so we can compare the two.

```{r clean and transform, echo=FALSE}
# Clean and transform each of the individual dfs
global_cases <- global_cases %>%
  pivot_longer(cols = 
                 -c('Province/State', 'Country/Region', 'Lat', 'Long'),
               names_to = "date",
               values_to = "cases")

global_deaths <- global_deaths %>%
  pivot_longer(cols = -c('Province/State', 'Country/Region', 'Lat', 'Long'),
               names_to = "date",
               values_to = "deaths")

US_cases <- US_cases %>%
  select(-c(UID, iso2, iso3, code3, FIPS, Country_Region)) %>%
  pivot_longer(cols = -c('Province_State', 'Admin2', 'Lat', 'Long_', 'Combined_Key' ),
               names_to = "date",
               values_to = "cases") %>%
  mutate(date=mdy(date))

US_deaths <- US_deaths %>%
  select(-c(UID, iso2, iso3, code3, FIPS, Country_Region)) %>%
  pivot_longer(cols = -c('Province_State', 'Admin2', 'Lat', 'Long_', 'Combined_Key', 'Population'),
               names_to = "date",
               values_to = "deaths") %>%
  mutate(date=mdy(date))

# Join global cases with global deaths
global <- global_cases %>%
  full_join(global_deaths) %>%
  rename(Country_Region = 'Country/Region',
         Province_State = 'Province/State') %>%
  mutate(date=mdy(date))

# Join US cases with US deaths
US <- US_cases %>%
  full_join(US_deaths)

# Filter out data that includes 0 cases
global <- global %>%
  filter(cases>0)
US <- US %>%
  filter(cases>0)

# Make global more comparable to US
global <- global %>%
  unite("Combined_Key",
        c(Province_State, Country_Region),
        sep = ", ",
        na.rm = TRUE,
        remove = FALSE)

# Prepare country population data for joining to global COVID-19 data
uid <- read_csv(uid_lookup_url) %>%
  select(-c(UID:FIPS, Combined_Key, Lat, Long_, Admin2))

# Join global pop to global counts
global <- global %>%
  left_join(uid, by = c("Province_State", "Country_Region")) 

# Add deaths per 1 million population and percent cases that resulted in death
US_by_state <- US %>%
  group_by(Province_State, date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths),
            Population = sum(Population)) %>%
  mutate(deaths_per_mill = deaths *1000000/Population,
         impact = (deaths/cases*100)) %>%
  select(Province_State, date, cases, deaths, deaths_per_mill, impact, Population) %>%
  ungroup()

global_by_country <- global %>%
  group_by(Country_Region, date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths),
            Population = sum(Population)) %>%
  mutate(deaths_per_mill = deaths *1000000/Population,
         impact = (deaths/cases*100)) %>%
  select(Country_Region, date, cases, deaths, deaths_per_mill, impact, Population) %>%
  ungroup()

# Compare the new dataframes
print(US_by_state)
print(global_by_country)
```

Now that we have data structures that look comparable lets examine it in a more digestable way.

### Visualizations and Analysis

First lets take a look at the total cases and deaths globally and then in the U.S.A.

```{r, fig.width=10, fig.height=6, echo=FALSE}
US_totals <- US_by_state %>%
  group_by(date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths),
            Population = sum(Population)) %>%
  mutate(deaths_per_mill = deaths *1000000/Population,
         impact = (deaths/cases*100)) %>%
  select(date, cases, deaths, deaths_per_mill, impact, Population) %>%
  ungroup()


global_totals <- global_by_country %>%
  group_by(date) %>%
  summarize(cases = sum(cases), deaths = sum(deaths),
            Population = sum(Population)) %>%
  mutate(deaths_per_mill = deaths *1000000/Population,
         impact = (deaths/cases*100)) %>%
  select(date, cases, deaths, deaths_per_mill, impact, Population) %>%
  ungroup()

# Combine global and US data into one dataframe
combined_data <- bind_rows(
  global_totals %>% mutate(location = "Global"),
  US_totals %>% mutate(location = "US")
)

# Plot cases and deaths for both global and US data
combined_data %>%
  ggplot(aes(x=date)) +
  geom_line(aes(y=cases, color="cases")) +
  geom_point(aes(y=cases, color="cases")) +
  geom_line(aes(y=deaths, color="deaths")) +
  geom_point(aes(y=deaths, color="deaths")) +
  scale_y_log10() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90)) +
  labs(title = "COVID19: Global vs US", y= NULL, color = "Metric") +
  facet_wrap(~location, scales = "free_y")

```

The trend between the two data sets seems to be similar. Lets see how they each do when considering the previously defined impact score.

```{r, fig.width=10, fig.height=6, echo=FALSE}
# Combine global and US data into one dataframe for impact
combined_impact_data <- bind_rows(
  global_by_country %>% 
    group_by(date) %>%
    summarize(impact = sum(deaths) / sum(cases) * 100) %>%
    mutate(location = "Global"),
  
  US_by_state %>% 
    group_by(date) %>%
    summarize(impact = sum(deaths) / sum(cases) * 100) %>%
    mutate(location = "US")
)

# Plot impact for both global and US data
combined_impact_data %>%
  ggplot(aes(x=date, y=impact, color=location)) +
  geom_line() +
  geom_point() +
  theme(legend.position = "bottom",
        axis.text.x = element_text(angle = 90)) +
  labs(title = "COVID19 Impact: Global vs US", y= "Impact (%)", color = "Location")
```

The impacts seem to again follow a similar trend. Lets see how the global impact relates to the U.S. impact using a linear regression model.

```{r, echo=FALSE}
# Summarize impact for global data by date
global_impact_summary <- global_by_country %>%
  group_by(date) %>%
  summarize(global_impact = sum(deaths) / sum(cases) * 100)

# Summarize impact for US data by date
US_impact_summary <- US_by_state %>%
  group_by(date) %>%
  summarize(US_impact = sum(deaths) / sum(cases) * 100)

# Merge the two datasets based on date
merged_impact_data <- inner_join(global_impact_summary, US_impact_summary, by = "date")

# Fit a linear regression model
lm_fit <- lm(US_impact ~ global_impact, data = merged_impact_data)

# Display the summary of the model
summary(lm_fit)
```

This results, not surprisingly, suggest that there is a strong correlation between the global impact and the U.S. impact.

Lets do a little validation.

```{r, fig.width=10, fig.height=6, echo=FALSE}
# Scatter plot with regression line
ggplot(merged_impact_data, aes(x = global_impact, y = US_impact)) +
  geom_point(aes(color = date), alpha = 0.6) +  # Scatter points colored by date
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Regression line
  labs(
    title = "Relationship between Global and U.S. Impact",
    x = "Global Impact (%)",
    y = "U.S. Impact (%)",
    caption = "Red line represents the linear regression fit"
  ) +
  theme_minimal()
```


```{r, fig.width=10, fig.height=6, echo=FALSE}
# Extract residuals and fitted values from the model
residuals <- residuals(lm(US_impact ~ global_impact, data = merged_impact_data))
fitted_values <- fitted(lm(US_impact ~ global_impact, data = merged_impact_data))

# Create the residual plot
ggplot(data = NULL, aes(x = fitted_values, y = residuals)) +
  geom_point(aes(color = residuals), alpha = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  theme_minimal() +
  labs(title = "Residual Plot",
       x = "Fitted Values",
       y = "Residuals",
       caption = "Red dashed line represents y = 0") +
  scale_color_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0)
```

```{r, echo=FALSE}
# Fit the linear regression model
model <- lm(US_impact ~ global_impact, data = merged_impact_data)

# Perform the Breusch-Pagan test
bp_test <- bptest(model)

# Print the results
print(bp_test)
```

This all pretty clearly confirms there is a statistically significant correlation. 

Given the close correlation lets use the average impact score to determine how the U.S. did compared to the whole world. 

```{r}
# Calculate the average impact scores for both US and global data
avg_US_impact <- mean(US_totals$impact, na.rm = TRUE)
avg_global_impact <- mean(global_by_country$impact, na.rm = TRUE)

# Compare the average US impact to the average global impact
comparison <- ifelse(avg_US_impact < avg_global_impact, 'better', 'worse')

list(avg_US_impact = avg_US_impact, avg_global_impact = avg_global_impact, comparison = comparison)
```

So the U.S. appears to have done at leasts a little better.

Just for fun lets look at how each state compares by impact score using a heatmap.

```{r, fig.width=10, fig.height=6, echo=FALSE}
# Aggregate data by state to get average impact for each state using the US_by_state dataframe
US_aggregated <- US_by_state %>%
  group_by(Province_State) %>%
  summarize(avg_impact = mean(impact, na.rm = TRUE))

# Merge the spatial data with the US_aggregated dataframe
us_states_merged <- left_join(us_states, US_aggregated, by = c("name" = "Province_State"))

# Create a map with filled states using leaflet
leaflet(us_states_merged) %>%
  addProviderTiles(providers$CartoDB.Positron) %>%
  addPolygons(fillColor = ~colorQuantile("YlOrRd", us_states_merged$avg_impact, na.color = "transparent")(avg_impact),
              weight = 1,
              opacity = 1,
              color = "white",
              dashArray = "3",
              fillOpacity = 0.7,
              highlight = highlightOptions(
                weight = 2,
                color = "#666",
                dashArray = "",
                fillOpacity = 0.7,
                bringToFront = TRUE),
              label = ~paste0(name, ": ", round(avg_impact, 2), "%")) %>%
  addLegend(pal = colorQuantile("YlOrRd", us_states_merged$avg_impact, na.color = "transparent"), 
            values = us_states_merged$avg_impact, 
            title = "Impact Percentage",
            position = "bottomright")
```

### Issues

1. While John Hopkins is a reputable source for data there can be bias introduced based on the reporting of cases and deaths.
2. In the context of a pandemic using past data to try and predict anything is going to be problematic at best without accounting for how various factors such as pandemic response has changed over time.
3. Defining impact score as death/cases*100 is simplistic and leaves out things such as hospitalizations and long-term health effects.
4. No where are external factors such as healthcare infrastructure, public health guidelines, and socio-economic conditions.
5. The global data set was too large to create a heatmap given local hardware limitations and the leaflet library's ability to hand large data.

```{r session info}
sessionInfo()
```